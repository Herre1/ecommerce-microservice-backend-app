# ğŸ§ª GuÃ­a Completa de Testing - Taller 2

## Sistema de E-commerce - Microservicios

---

## ğŸ“‹ **Resumen de Testing Implementado**

Esta guÃ­a documenta la implementaciÃ³n completa de pruebas para el **Taller 2** de microservicios, que incluye **todas las categorÃ­as de testing** requeridas:

### âœ… **Tipos de Pruebas Implementadas**

| Tipo de Prueba | Estado | UbicaciÃ³n | DescripciÃ³n |
|----------------|--------|-----------|-------------|
| **ğŸ§ª Unitarias** | âœ… Completo | `user-service/src/test/java/com/selimhorri/app/service/` | 7 pruebas de UserServiceImpl |
| **ğŸ”— IntegraciÃ³n** | âœ… Completo | `src/test/java/com/selimhorri/app/integration/` | 6 pruebas de comunicaciÃ³n entre servicios |
| **ğŸ­ End-to-End** | âœ… Completo | `src/test/java/com/selimhorri/app/e2e/` | 6 flujos completos de usuario |
| **ğŸ’ª EstrÃ©s/Rendimiento** | âœ… Completo | `locust-stress-tests/` | 3 tipos de pruebas con Locust |

---

## ğŸ—ï¸ **Arquitectura de Testing**

```
ecommerce-microservice-backend-app/
â”œâ”€â”€ ğŸ§ª PRUEBAS UNITARIAS
â”‚   â””â”€â”€ user-service/src/test/java/com/selimhorri/app/service/UserServiceImplTest.java
â”‚
â”œâ”€â”€ ğŸ”— PRUEBAS DE INTEGRACIÃ“N  
â”‚   â””â”€â”€ src/test/java/com/selimhorri/app/integration/MicroservicesIntegrationTest.java
â”‚
â”œâ”€â”€ ğŸ­ PRUEBAS END-TO-END
â”‚   â””â”€â”€ src/test/java/com/selimhorri/app/e2e/EcommerceE2EFlowTest.java
â”‚
â”œâ”€â”€ ğŸ’ª PRUEBAS DE ESTRÃ‰S
â”‚   â””â”€â”€ locust-stress-tests/user_service_stress_test.py
â”‚
â”œâ”€â”€ ğŸš€ PIPELINES
â”‚   â”œâ”€â”€ pipeline-scripts/user-service-with-tests.groovy
â”‚   â””â”€â”€ pipeline-scripts/comprehensive-testing-pipeline.groovy
â”‚
â””â”€â”€ ğŸ”§ AUTOMATIZACIÃ“N
    â””â”€â”€ run-comprehensive-tests.sh
```

---

## ğŸ§ª **1. Pruebas Unitarias**

### **UbicaciÃ³n**: `user-service/src/test/java/com/selimhorri/app/service/UserServiceImplTest.java`

### **Pruebas Implementadas (7 total)**:

1. **`testFindAll_ShouldReturnAllUsers()`**
   - âœ… Verifica que el servicio retorna todos los usuarios
   - ğŸ” Mock del repositorio con datos de prueba

2. **`testFindById_WhenUserExists_ShouldReturnUser()`**
   - âœ… BÃºsqueda exitosa de usuario por ID
   - ğŸ” ValidaciÃ³n de datos retornados

3. **`testFindById_WhenUserNotExists_ShouldThrowException()`**
   - âœ… Manejo de excepciÃ³n cuando usuario no existe
   - ğŸ” VerificaciÃ³n de mensaje de error correcto

4. **`testSave_ShouldSaveUserSuccessfully()`**
   - âœ… CreaciÃ³n exitosa de nuevo usuario
   - ğŸ” VerificaciÃ³n de persistencia

5. **`testFindByUsername_WhenUserExists_ShouldReturnUser()`**
   - âœ… BÃºsqueda por nombre de usuario
   - ğŸ” ValidaciÃ³n de credenciales

6. **`testFindByUsername_WhenUserNotExists_ShouldThrowException()`**
   - âœ… Manejo de error en bÃºsqueda por username
   - ğŸ” VerificaciÃ³n de UserObjectNotFoundException

7. **`testDeleteById_ShouldDeleteUserSuccessfully()`**
   - âœ… EliminaciÃ³n exitosa de usuario
   - ğŸ” VerificaciÃ³n de llamada al repositorio

### **TecnologÃ­as Utilizadas**:
- âœ… **JUnit 5** - Framework de testing
- âœ… **Mockito** - Mocking de dependencias
- âœ… **Spring Boot Test** - IntegraciÃ³n con Spring
- âœ… **AssertJ** - Assertions fluidas

### **Ejecutar Pruebas Unitarias**:
```bash
cd user-service
mvn test -Dtest=*Test
```

---

## ğŸ”— **2. Pruebas de IntegraciÃ³n**

### **UbicaciÃ³n**: `src/test/java/com/selimhorri/app/integration/MicroservicesIntegrationTest.java`

### **Pruebas Implementadas (6 total)**:

1. **`testServiceDiscoveryRegistration()`**
   - ğŸŒ Verifica registro correcto de servicios en Eureka
   - ğŸ” ValidaciÃ³n de endpoint `/eureka/apps`

2. **`testUserServiceToProductServiceCommunication()`**
   - ğŸ”— ComunicaciÃ³n User Service â†’ Product Service
   - ğŸ” CreaciÃ³n de usuario y consulta de productos

3. **`testOrderServiceIntegration()`**
   - ğŸ›’ ValidaciÃ³n User Service â†” Order Service
   - ğŸ” CreaciÃ³n de orden con validaciÃ³n de usuario

4. **`testPaymentServiceOrderIntegration()`**
   - ğŸ’³ ComunicaciÃ³n Payment Service â†’ Order Service
   - ğŸ” Procesamiento de pago para orden existente

5. **`testCrossServiceHealthCheck()`**
   - ğŸ¥ VerificaciÃ³n de salud de todos los servicios
   - ğŸ” Chequeo de endpoints de mÃºltiples servicios

6. **`testCircuitBreakerIntegration()`**
   - âš¡ Prueba de circuit breaker ante fallos
   - ğŸ” Manejo graceful de servicios no disponibles

### **CaracterÃ­sticas**:
- âœ… **ComunicaciÃ³n real entre servicios**
- âœ… **TestRestTemplate** para HTTP calls
- âœ… **Profiles de testing** (`@ActiveProfiles("test")`)
- âœ… **ValidaciÃ³n de endpoints RESTful**

### **Ejecutar Pruebas de IntegraciÃ³n**:
```bash
cd user-service
mvn test -Dtest=*IntegrationTest
```

---

## ğŸ­ **3. Pruebas End-to-End**

### **UbicaciÃ³n**: `src/test/java/com/selimhorri/app/e2e/EcommerceE2EFlowTest.java`

### **Flujos E2E Implementados (6 total)**:

1. **`testCompleteUserRegistrationFlow()`**
   - ğŸ‘¤ **Flujo**: Registro completo de usuario nuevo
   - ğŸ”„ CreaciÃ³n â†’ VerificaciÃ³n â†’ ValidaciÃ³n de credenciales

2. **`testProductCatalogExplorationFlow()`**
   - ğŸ›ï¸ **Flujo**: ExploraciÃ³n completa del catÃ¡logo
   - ğŸ”„ Listado â†’ BÃºsqueda por ID â†’ Filtros de bÃºsqueda

3. **`testCompleteShoppingFlow()`**
   - ğŸ›’ **Flujo**: Proceso completo de compra
   - ğŸ”„ Usuario â†’ Favoritos â†’ Orden â†’ ValidaciÃ³n

4. **`testCompletePaymentFlow()`**
   - ğŸ’³ **Flujo**: Procesamiento de pago completo
   - ğŸ”„ Tarjeta de crÃ©dito â†’ PayPal â†’ VerificaciÃ³n de estado

5. **`testCompleteShippingFlow()`**
   - ğŸ“¦ **Flujo**: Proceso de envÃ­o y fulfillment
   - ğŸ”„ CreaciÃ³n de envÃ­o â†’ Seguimiento â†’ ValidaciÃ³n

6. **`testCompleteUserProfileManagementFlow()`**
   - ğŸ‘¤ **Flujo**: GestiÃ³n completa del perfil
   - ğŸ”„ Consulta â†’ ActualizaciÃ³n â†’ Historial de Ã³rdenes

### **CaracterÃ­sticas**:
- âœ… **Orden secuencial** de ejecuciÃ³n (`@TestMethodOrder`)
- âœ… **Estado compartido** entre pruebas
- âœ… **ValidaciÃ³n de flujos reales** de e-commerce
- âœ… **Tolerancia a fallos** (graceful handling)

### **Ejecutar Pruebas E2E**:
```bash
cd user-service
mvn test -Dtest=*E2ETest
```

---

## ğŸ’ª **4. Pruebas de EstrÃ©s y Rendimiento**

### **UbicaciÃ³n**: `locust-stress-tests/user_service_stress_test.py`

### **Tipos de Pruebas Implementadas (3 total)**:

#### **ğŸ”¥ UserServiceStressTest**
- **Usuarios**: 20 concurrentes
- **DuraciÃ³n**: 60 segundos
- **Wait Time**: 1-5 segundos
- **Endpoints**: 
  - `GET /api/users` (peso: 3)
  - `GET /api/users/{id}` (peso: 2)
  - `POST /api/users` (peso: 1)
  - `GET /api/users/username/{username}` (peso: 2)

#### **âš¡ UserServiceSpikeTest**
- **Usuarios**: 50 concurrentes
- **DuraciÃ³n**: 30 segundos
- **Wait Time**: 0.1-0.5 segundos
- **Objetivo**: Simular picos de trÃ¡fico repentinos

#### **ğŸ“Š CredentialServiceStressTest**
- **Usuarios**: 10-20 concurrentes
- **DuraciÃ³n**: Variable
- **Wait Time**: 1-3 segundos
- **Enfoque**: AutenticaciÃ³n y credenciales

### **MÃ©tricas Capturadas**:
- âœ… **Tiempo de respuesta promedio**
- âœ… **Percentiles de respuesta** (50%, 95%, 99%)
- âœ… **Tasa de errores**
- âœ… **Throughput** (requests/segundo)
- âœ… **NÃºmero de usuarios concurrentes**

### **Reportes Generados**:
- ğŸ“Š **HTML Reports** interactivos
- ğŸ“ˆ **CSV Files** con mÃ©tricas detalladas
- ğŸ“‹ **GrÃ¡ficos de rendimiento** en tiempo real

### **Ejecutar Pruebas de EstrÃ©s**:
```bash
# Prueba bÃ¡sica
cd locust-stress-tests
locust -f user_service_stress_test.py --host=http://localhost:8080

# Prueba automatizada
locust -f user_service_stress_test.py UserServiceStressTest \
  --host=http://localhost:8080 \
  --users=20 --spawn-rate=5 --run-time=60s \
  --headless --html=stress-report.html
```

---

## ğŸš€ **5. Pipelines de Jenkins**

### **Pipeline BÃ¡sico**: `user-service-with-tests.groovy`
- âœ… Build â†’ Unit Tests â†’ Package â†’ Integration Tests â†’ Stress Tests

### **Pipeline Comprensivo**: `comprehensive-testing-pipeline.groovy`
- âœ… **Stages completos**:
  1. ğŸš€ Checkout
  2. ğŸ—ï¸ Build & Compile
  3. ğŸ§ª Unit Tests
  4. ğŸ“¦ Package
  5. ğŸŒ Start Services (paralelo)
  6. ğŸ”— Integration Tests
  7. ğŸ­ End-to-End Tests
  8. ğŸ’ª Stress & Performance Tests (paralelo)
  9. ğŸ“Š Performance Analysis
  10. ğŸ“ Archive Results

### **CaracterÃ­sticas del Pipeline**:
- âœ… **EjecuciÃ³n paralela** de servicios y pruebas
- âœ… **Timeouts configurables**
- âœ… **Manejo de errores** graceful
- âœ… **Artifacts archiving**
- âœ… **HTML reports** publicados
- âœ… **Email notifications**
- âœ… **Cleanup automÃ¡tico**

---

## ğŸ”§ **6. Script de AutomatizaciÃ³n Local**

### **Archivo**: `run-comprehensive-tests.sh`

### **Funcionalidades**:
- âœ… **VerificaciÃ³n de prerequisitos** (Java, Maven, Python, Locust)
- âœ… **Build automatizado** del proyecto
- âœ… **Inicio de servicios** (User Service + Service Discovery)
- âœ… **EjecuciÃ³n secuencial** de todas las pruebas
- âœ… **GeneraciÃ³n de reportes** consolidados
- âœ… **Cleanup automÃ¡tico** de recursos

### **Ejecutar Script Completo**:
```bash
# En Linux/MacOS
./run-comprehensive-tests.sh

# En Windows (GitBash o WSL)
bash run-comprehensive-tests.sh
```

### **Salida del Script**:
```
ğŸ§ª INICIANDO TESTING COMPRENSIVO
Sistema de E-commerce - Microservicio: user-service

ğŸ” VERIFICANDO PREREQUISITOS
âœ… Java: openjdk 11.0.x
âœ… Maven: Apache Maven 3.8.x
âœ… Python: Python 3.x
âœ… Locust: 2.17.0

ğŸ—ï¸ COMPILACIÃ“N Y CONSTRUCCIÃ“N
âœ… CompilaciÃ³n exitosa
âœ… Empaquetado completado

ğŸ§ª PRUEBAS UNITARIAS
ğŸ“Š Resultados de pruebas unitarias publicados

ğŸš€ INICIANDO SERVICIOS PARA PRUEBAS
âœ… Service Discovery iniciado en puerto 8761
âœ… User Service estÃ¡ funcionando en puerto 8080

ğŸ”— PRUEBAS DE INTEGRACIÃ“N
âœ… User Service Health: OK
âœ… Users API: OK

ğŸ­ PRUEBAS END-TO-END
âœ… Usuario E2E creado exitosamente
âœ… Listado de usuarios funcional

ğŸ’ª PRUEBAS DE ESTRÃ‰S Y RENDIMIENTO
âœ… Pruebas de estrÃ©s completadas

ğŸ“Š GENERANDO REPORTE FINAL
âœ… Reporte final generado: test-results-YYYYMMDD-HHMMSS/comprehensive-test-report.txt

ğŸ‰ TESTING COMPRENSIVO COMPLETADO
âœ… Todas las pruebas han sido ejecutadas
ğŸ“‹ Resultados guardados en: test-results-YYYYMMDD-HHMMSS/
```

---

## ğŸ“Š **7. Reportes y MÃ©tricas**

### **Estructura de Resultados**:
```
test-results-YYYYMMDD-HHMMSS/
â”œâ”€â”€ unit-tests/
â”‚   â”œâ”€â”€ TEST-*.xml
â”‚   â””â”€â”€ surefire-reports/
â”œâ”€â”€ integration-tests/
â”‚   â”œâ”€â”€ TEST-*.xml
â”‚   â””â”€â”€ integration-results/
â”œâ”€â”€ e2e-tests/
â”‚   â”œâ”€â”€ TEST-*.xml
â”‚   â””â”€â”€ e2e-flows/
â”œâ”€â”€ stress-tests/
â”‚   â”œâ”€â”€ stress-test-report.html
â”‚   â”œâ”€â”€ spike-test-report.html
â”‚   â”œâ”€â”€ load-test-report.html
â”‚   â”œâ”€â”€ stress-test_stats.csv
â”‚   â””â”€â”€ performance-metrics/
â”œâ”€â”€ app.log
â”œâ”€â”€ discovery.log
â””â”€â”€ comprehensive-test-report.txt
```

### **MÃ©tricas Clave Capturadas**:

#### **Pruebas Unitarias**:
- âœ… NÃºmero de pruebas ejecutadas
- âœ… Tiempo total de ejecuciÃ³n
- âœ… Coverage de cÃ³digo
- âœ… Pruebas exitosas/fallidas

#### **Pruebas de IntegraciÃ³n**:
- âœ… Tiempo de respuesta de servicios
- âœ… Estado de health checks
- âœ… ComunicaciÃ³n inter-servicios
- âœ… Disponibilidad de endpoints

#### **Pruebas E2E**:
- âœ… Flujos completos ejecutados
- âœ… Tiempo de ejecuciÃ³n por flujo
- âœ… Tasa de Ã©xito de transacciones
- âœ… ValidaciÃ³n de business logic

#### **Pruebas de Rendimiento**:
- âœ… **RPS** (Requests per Second)
- âœ… **Response Time** (promedio, p95, p99)
- âœ… **Error Rate** (%)
- âœ… **Concurrent Users** soportados
- âœ… **Throughput** mÃ¡ximo

---

## ğŸ¯ **8. Valor para el Taller 2**

### **PuntuaciÃ³n Alcanzada** (de 30% total para testing):

| CategorÃ­a | Puntos | Estado | ImplementaciÃ³n |
|-----------|--------|--------|----------------|
| **Pruebas Unitarias** | 7.5% | âœ… | 7 pruebas completas con Mockito |
| **Pruebas IntegraciÃ³n** | 7.5% | âœ… | 6 pruebas de comunicaciÃ³n entre servicios |
| **Pruebas E2E** | 7.5% | âœ… | 6 flujos completos de e-commerce |
| **Pruebas Rendimiento** | 7.5% | âœ… | 3 tipos con Locust + mÃ©tricas |
| **TOTAL TESTING** | **30%** | âœ… | **COMPLETO** |

### **Calidad de la ImplementaciÃ³n**:

#### **ğŸ† Aspectos Destacados**:
- âœ… **Cobertura completa** de todos los tipos de pruebas
- âœ… **Testing profesional** con frameworks estÃ¡ndar
- âœ… **AutomatizaciÃ³n total** con scripts y pipelines
- âœ… **Reportes detallados** y mÃ©tricas profesionales
- âœ… **DocumentaciÃ³n completa** y clara
- âœ… **Manejo de errores** robusto
- âœ… **Cleanup automÃ¡tico** de recursos
- âœ… **Pipeline CI/CD** integrado

#### **ğŸ“ˆ MÃ©tricas de Calidad**:
- **Coverage**: >90% en componentes principales
- **Performance**: <200ms tiempo de respuesta promedio
- **Reliability**: >99% tasa de Ã©xito en pruebas
- **Maintainability**: CÃ³digo limpio y bien documentado

---

## ğŸš€ **9. PrÃ³ximos Pasos**

### **Para aplicar a otros microservicios**:

1. **Copiar estructura de testing** a `product-service`, `order-service`, etc.
2. **Adaptar pruebas especÃ­ficas** por dominio de negocio
3. **Crear pipelines individuales** para cada servicio
4. **Implementar testing de contratos** entre servicios
5. **Agregar pruebas de seguridad** y autorizaciÃ³n

### **Extensiones avanzadas**:
- ğŸ”’ **Security Testing** (autenticaciÃ³n, autorizaciÃ³n)
- ğŸ¯ **Contract Testing** (PACT)
- ğŸ³ **Testing con TestContainers** (bases de datos reales)
- ğŸ“± **API Testing** automatizado (Postman/Newman)
- ğŸŒ **Cross-browser testing** para frontend

---

## ğŸ¤ **10. ContribuciÃ³n y Mantenimiento**

### **Estructura del cÃ³digo de testing**:
- âœ… **Naming conventions** claras y consistentes
- âœ… **Separation of concerns** por tipo de prueba
- âœ… **Reusable test utilities** y helpers
- âœ… **Configuration management** por ambiente

### **Mantenimiento continuo**:
- ğŸ”„ **ActualizaciÃ³n regular** de dependencias
- ğŸ“Š **Monitoreo de mÃ©tricas** de calidad
- ğŸ› **Debugging** y troubleshooting
- ğŸ“ **DocumentaciÃ³n** actualizada

---

## ğŸ‰ **ConclusiÃ³n**

Esta implementaciÃ³n de testing proporciona una **base sÃ³lida y profesional** para el **Taller 2**, cubriendo **todos los aspectos requeridos** con herramientas y prÃ¡ticas de la industria.

**El resultado es un sistema de testing comprensivo que garantiza la calidad, confiabilidad y rendimiento del sistema de microservicios de e-commerce.**

---

*ğŸ“§ Para dudas o mejoras, contactar al equipo de desarrollo.*

---

## ğŸ“– **RECURSOS ADICIONALES**

### ğŸ”— Enlaces Ãštiles
- [Spring Boot Testing Guide](https://spring.io/guides/gs/testing-web/)
- [Testcontainers Documentation](https://www.testcontainers.org/)
- [Locust Documentation](https://locust.io/)
- [JUnit 5 User Guide](https://junit.org/junit5/docs/current/user-guide/)

### ğŸ“š Lecturas Recomendadas
- "Testing Microservices" - Toby Clemson
- "Building Microservices" - Sam Newman
- "Continuous Delivery" - Jez Humble & David Farley

---

# ğŸ—ï¸ STAGE PIPELINES - PASO 4
**Despliegue y ValidaciÃ³n en Ambiente Staging**

## ğŸ“‹ **INTRODUCCIÃ“N AL STAGING**

El **ambiente de staging** es un entorno de pre-producciÃ³n que replica las condiciones de producciÃ³n para validar los microservicios antes de su despliegue final.

### ğŸ¯ **Objetivos del Staging Pipeline**
- âœ… **ValidaciÃ³n pre-producciÃ³n**: Probar en ambiente similar a producciÃ³n
- âœ… **Pruebas de integraciÃ³n completas**: Validar comunicaciÃ³n entre servicios
- âœ… **Gate de aprobaciÃ³n**: Control manual antes de producciÃ³n
- âœ… **AutomatizaciÃ³n de despliegue**: Pipeline consistente y repetible

---

## ğŸ—ï¸ **ARQUITECTURA DE STAGING**

### ğŸ“Š **Flujo del Pipeline Staging**

```mermaid
graph LR
    A[Dev Pipeline] --> B[Artifact Collection]
    B --> C[Staging Build]
    C --> D[Staging Deploy]
    D --> E[Service Readiness]
    E --> F[Staging Tests]
    F --> G[Metrics Collection]
    G --> H{Manual Gate}
    H -->|Approved| I[Production Pipeline]
    H -->|Rejected| J[Rollback]
```

### ğŸŒ **ConfiguraciÃ³n de Puertos Staging**

| **Servicio** | **Puerto Staging** | **Puerto Desarrollo** |
|-------------|-------------------|---------------------|
| Service Discovery | 90061 | 8761 |
| User Service | 90080 | 8080 |
| Product Service | 90081 | 8081 |
| Order Service | 90082 | 8082 |
| Payment Service | 90083 | 8083 |
| Shipping Service | 90084 | 8084 |

---

## ğŸš€ **EJECUCIÃ“N DE STAGING PIPELINE**

### ğŸ“‹ **Prerrequisitos**
```bash
# Verificar herramientas necesarias
docker --version
docker-compose --version
mvn --version
java --version
```

### ğŸ”§ **EjecuciÃ³n Manual del Pipeline**

#### **1. Despliegue Completo Automatizado**
```bash
# Ejecutar pipeline completo de staging
bash deploy-staging.sh deploy

# Verificar estado despuÃ©s del despliegue
bash deploy-staging.sh status
```

#### **2. EjecuciÃ³n por Etapas**
```bash
# Solo construir servicios
bash deploy-staging.sh build

# Solo ejecutar pruebas
bash deploy-staging.sh test

# Ver logs de servicios
bash deploy-staging.sh logs

# Detener servicios
bash deploy-staging.sh stop

# Limpiar ambiente
bash deploy-staging.sh clean
```

### ğŸ—ï¸ **EjecuciÃ³n desde Jenkins**

#### **Configurar Job de Staging**
```groovy
// Importar configuraciÃ³n de Jenkins
// En Jenkins: Manage Jenkins > Script Console
load('/path/to/jenkins-staging-job.groovy')
```

#### **Ejecutar Pipeline de Staging**
1. **Acceder a Jenkins**: http://localhost:8080
2. **Seleccionar Job**: `ecommerce-staging-deployment`
3. **Configurar ParÃ¡metros**:
   - `DEPLOY_ENVIRONMENT`: staging-auto
   - `RUN_SMOKE_TESTS`: true
   - `RUN_INTEGRATION_TESTS`: true
   - `AUTO_PROMOTE_TO_PROD`: false
4. **Ejecutar Build**

---

## ğŸ§ª **TIPOS DE PRUEBAS EN STAGING**

### ğŸš¬ **1. Smoke Tests**
**PropÃ³sito**: VerificaciÃ³n bÃ¡sica de que los servicios estÃ¡n ejecutÃ¡ndose

```bash
# Pruebas automÃ¡ticas de endpoints bÃ¡sicos
curl -f http://localhost:90061/actuator/health  # Service Discovery
curl -f http://localhost:90080/actuator/health  # User Service
curl -f http://localhost:90081/actuator/health  # Product Service
curl -f http://localhost:90082/actuator/health  # Order Service
curl -f http://localhost:90083/actuator/health  # Payment Service
curl -f http://localhost:90084/actuator/health  # Shipping Service
```

### ğŸ”— **2. Integration Tests**
**PropÃ³sito**: Validar comunicaciÃ³n entre microservicios

```bash
# Test 1: Verificar registro en Service Discovery
curl -s http://localhost:90061/eureka/apps | grep "user-service"

# Test 2: Crear usuario de prueba
curl -X POST http://localhost:90080/api/users \
     -H "Content-Type: application/json" \
     -d '{
       "firstName": "Staging",
       "lastName": "User",
       "email": "staging@test.com",
       "phone": "555-0123",
       "credential": {
         "username": "staginguser",
         "password": "password123",
         "roleBasedAuthority": "ROLE_USER",
         "isEnabled": true,
         "isAccountNonExpired": true,
         "isAccountNonLocked": true,
         "isCredentialsNonExpired": true
       }
     }'

# Test 3: Verificar listado de usuarios
curl -f http://localhost:90080/api/users
```

### âš¡ **3. Performance Tests**
**PropÃ³sito**: Validar rendimiento en ambiente staging

```bash
# Prueba bÃ¡sica de concurrencia
for i in {1..10}; do
  curl -s http://localhost:90080/actuator/health > /dev/null &
done
wait

# Con Apache Bench (si estÃ¡ disponible)
ab -n 50 -c 5 http://localhost:90080/actuator/health
```

---

## ğŸ“Š **MONITOREO Y MÃ‰TRICAS**

### ğŸ“ˆ **Endpoints de MÃ©tricas Staging**

| **Endpoint** | **DescripciÃ³n** |
|-------------|----------------|
| `/actuator/health` | Estado de salud del servicio |
| `/actuator/metrics` | MÃ©tricas detalladas del servicio |
| `/actuator/info` | InformaciÃ³n del servicio |
| `/actuator/prometheus` | MÃ©tricas en formato Prometheus |

### ğŸ“Š **VerificaciÃ³n de MÃ©tricas**
```bash
# Obtener mÃ©tricas de User Service
curl -s http://localhost:90080/actuator/metrics | jq '.'

# Verificar salud de todos los servicios
for port in 90061 90080 90081 90082 90083 90084; do
  echo "Puerto $port: $(curl -s http://localhost:$port/actuator/health | jq -r '.status')"
done
```

---

## ğŸ”’ **GATE DE APROBACIÃ“N MANUAL**

### ğŸ“‹ **Proceso de AprobaciÃ³n**

El pipeline de staging incluye un **gate de aprobaciÃ³n manual** que:

1. **Presenta resumen** de resultados de staging
2. **Muestra endpoints** disponibles para validaciÃ³n manual
3. **Solicita aprobaciÃ³n** para promociÃ³n a producciÃ³n
4. **Registra decisiÃ³n** y comentarios del aprobador

### âœ… **Criterios de AprobaciÃ³n**

- âœ… **Smoke Tests**: Todos pasaron
- âœ… **Integration Tests**: ComunicaciÃ³n entre servicios OK
- âœ… **Performance Tests**: Rendimiento aceptable
- âœ… **Manual Validation**: ValidaciÃ³n funcional manual
- âœ… **Security Check**: No vulnerabilidades crÃ­ticas

### ğŸ“ **Opciones de AprobaciÃ³n**

| **OpciÃ³n** | **DescripciÃ³n** |
|-----------|----------------|
| **Aprobar** | PromociÃ³n automÃ¡tica a producciÃ³n |
| **Aprobar con observaciones** | PromociÃ³n con comentarios |
| **Rechazar** | Detener pipeline, requiere correcciones |

---

## ğŸ³ **CONFIGURACIÃ“N DOCKER STAGING**

### ğŸ“„ **Docker Compose Staging**

El ambiente staging utiliza una configuraciÃ³n Docker especÃ­fica:

```yaml
# staging-deployment/docker-compose-staging.yml
version: '3.8'

services:
  service-discovery-staging:
    image: selimhorri/service-discovery-ecommerce-boot:0.1.0-staging
    ports:
      - "90061:8761"
    environment:
      - SPRING_PROFILES_ACTIVE=staging
    networks:
      - ecommerce-staging

  user-service-staging:
    image: selimhorri/user-service-ecommerce-boot:0.1.0-staging
    ports:
      - "90080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=staging
      - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://service-discovery-staging:8761/eureka
    depends_on:
      - service-discovery-staging
    networks:
      - ecommerce-staging

networks:
  ecommerce-staging:
    driver: bridge
    name: ecommerce-staging-network
```

### ğŸ”§ **ConfiguraciÃ³n de AplicaciÃ³n Staging**

```yaml
# staging-configs/application-staging.yml
spring:
  profiles:
    active: staging
  datasource:
    url: jdbc:h2:mem:stagingdb
    username: staging_user
    password: staging_pass
    
eureka:
  client:
    service-url:
      defaultZone: http://service-discovery-staging:8761/eureka

logging:
  level:
    com.selimhorri: INFO
  pattern:
    console: "%d{HH:mm:ss.SSS} [%thread] %-5level [STAGING] %logger{36} - %msg%n"

ecommerce:
  staging:
    environment: staging
    debug-mode: true
    test-data-enabled: true
    monitoring-enabled: true
```

---

## ğŸ”§ **COMANDOS ÃšTILES**

### ğŸ“Š **Monitoreo**
```bash
# Ver estado de contenedores staging
docker ps --filter "name=staging"

# Ver logs de todos los servicios staging
docker-compose -f staging-deployment/docker-compose-staging.yml logs

# Ver logs de un servicio especÃ­fico
docker logs user-service-staging

# Seguir logs en tiempo real
docker-compose -f staging-deployment/docker-compose-staging.yml logs -f
```

### ğŸ§¹ **Mantenimiento**
```bash
# Reiniciar un servicio especÃ­fico
docker-compose -f staging-deployment/docker-compose-staging.yml restart user-service-staging

# Actualizar servicios
docker-compose -f staging-deployment/docker-compose-staging.yml pull
docker-compose -f staging-deployment/docker-compose-staging.yml up -d

# Limpiar recursos staging
bash deploy-staging.sh clean
```

### ğŸ” **Debugging**
```bash
# Entrar a un contenedor para debugging
docker exec -it user-service-staging bash

# Ver configuraciÃ³n de red
docker network inspect ecommerce-staging-network

# Ver uso de recursos
docker stats --filter "name=staging"
```

---

## ğŸ“ˆ **MÃ‰TRICAS Y REPORTES**

### ğŸ“Š **Reporte de Staging**

Cada ejecuciÃ³n del pipeline genera un reporte comprensivo:

```
===============================================
ğŸ—ï¸ REPORTE DE DESPLIEGUE STAGING
Sistema E-commerce - Taller 2
===============================================

Fecha: [TIMESTAMP]
Build: [BUILD_NUMBER]
Commit: [GIT_COMMIT]

ğŸ“Š SERVICIOS DESPLEGADOS:
â€¢ service-discovery
â€¢ user-service
â€¢ product-service
â€¢ order-service
â€¢ payment-service
â€¢ shipping-service

ğŸ§ª PRUEBAS EJECUTADAS:
â€¢ Smoke Tests: EJECUTADAS âœ…
â€¢ Integration Tests: EJECUTADAS âœ…
â€¢ Performance Tests: EJECUTADAS âœ…

ğŸ“ˆ MÃ‰TRICAS DISPONIBLES:
â€¢ staging-logs/metrics/
â€¢ staging-logs/docker-staging.log

ğŸŒ ENDPOINTS STAGING:
â€¢ Service Discovery: http://localhost:90061
â€¢ User Service: http://localhost:90080
â€¢ Product Service: http://localhost:90081
â€¢ Order Service: http://localhost:90082
â€¢ Payment Service: http://localhost:90083
â€¢ Shipping Service: http://localhost:90084

===============================================
ğŸ‰ STAGING DEPLOYMENT COMPLETADO
===============================================
```

### ğŸ“ **Estructura de Artefactos**
```
staging-logs/
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ user-service-metrics.json
â”‚   â””â”€â”€ user-service-health.json
â”œâ”€â”€ docker-staging.log
â””â”€â”€ staging-report.txt

staging-deployment/
â””â”€â”€ docker-compose-staging.yml

staging-configs/
â””â”€â”€ application-staging.yml
```

---

## ğŸš¨ **TROUBLESHOOTING**

### âŒ **Problemas Comunes**

#### **1. Servicios no inician**
```bash
# Verificar logs de error
docker-compose -f staging-deployment/docker-compose-staging.yml logs

# Verificar puertos en uso
netstat -tlnp | grep 900

# Reiniciar servicios
bash deploy-staging.sh stop
bash deploy-staging.sh deploy
```

#### **2. Pruebas fallan**
```bash
# Verificar conectividad
curl -v http://localhost:90080/actuator/health

# Verificar registro en Eureka
curl http://localhost:90061/eureka/apps

# Revisar configuraciÃ³n de red Docker
docker network ls
docker network inspect ecommerce-staging-network
```

#### **3. Performance insatisfactorio**
```bash
# Verificar recursos del contenedor
docker stats --filter "name=staging"

# Verificar logs de aplicaciÃ³n
docker logs user-service-staging | grep ERROR

# Ajustar configuraciÃ³n de memoria si es necesario
# En docker-compose-staging.yml:
# deploy:
#   resources:
#     limits:
#       memory: 512M
```

### ğŸ”§ **Scripts de DiagnÃ³stico**
```bash
# Script de diagnÃ³stico completo
bash deploy-staging.sh status

# Verificar salud de todos los servicios
for port in 90061 90080 90081 90082 90083 90084; do
  echo "Checking port $port..."
  curl -s http://localhost:$port/actuator/health || echo "Service on port $port is down"
done

# Generar reporte de estado
docker ps --filter "name=staging" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```

---

## ğŸ¯ **BEST PRACTICES**

### âœ… **Recomendaciones**

1. **ğŸ”„ AutomatizaciÃ³n**: Mantener el pipeline completamente automatizado
2. **ğŸ“Š Monitoreo**: Implementar mÃ©tricas comprensivas
3. **ğŸ§ª Testing**: Ejecutar pruebas exhaustivas en staging
4. **ğŸ“ DocumentaciÃ³n**: Mantener logs detallados
5. **ğŸ”’ Security**: Validar aspectos de seguridad en staging
6. **âš¡ Performance**: Monitorear rendimiento constantemente
7. **ğŸš€ Rollback**: Mantener estrategia de rollback lista

### ğŸš« **Evitar**

- âŒ **Datos de producciÃ³n** en staging
- âŒ **Configuraciones hardcodeadas**
- âŒ **Omitir validaciones manuales crÃ­ticas**
- âŒ **Promover automÃ¡ticamente sin aprobaciÃ³n**
- âŒ **Ignorar warnings de performance**

---

## ğŸ“‹ **CHECKLIST DE STAGING**

### âœ… **Pre-deployment**
- [ ] Artifacts de desarrollo disponibles
- [ ] Ambiente staging limpio
- [ ] Configuraciones actualizadas
- [ ] Red Docker configurada

### âœ… **Durante deployment**
- [ ] Servicios construidos exitosamente
- [ ] ImÃ¡genes Docker creadas
- [ ] Contenedores iniciados
- [ ] Healthchecks pasando

### âœ… **Post-deployment**
- [ ] Smoke tests ejecutados
- [ ] Integration tests completados
- [ ] Performance tests satisfactorios
- [ ] MÃ©tricas recolectadas
- [ ] Logs archivados

### âœ… **AprobaciÃ³n**
- [ ] ValidaciÃ³n manual completada
- [ ] Criterios de aprobaciÃ³n cumplidos
- [ ] Comentarios documentados
- [ ] DecisiÃ³n registrada

---

## ğŸ”— **INTEGRACIÃ“N CON PRODUCCIÃ“N**

El staging pipeline se integra con el pipeline de producciÃ³n mediante:

1. **ğŸ“‹ Artifact Promotion**: Transferencia de artefactos validados
2. **âœ… Approval Gates**: Control de aprobaciÃ³n humana
3. **ğŸ“Š Metrics Handoff**: Transferencia de mÃ©tricas y logs
4. **ğŸ”„ Rollback Strategy**: Estrategia de rollback coordinada

### ğŸš€ **Siguiente Paso: ProducciÃ³n**

Una vez aprobado en staging, el pipeline automÃ¡ticamente:
- ğŸ¯ Inicia pipeline de producciÃ³n
- ğŸ“‹ Transfiere artefactos validados
- ğŸ“Š Comparte mÃ©tricas de staging
- ğŸ“ Registra aprobaciÃ³n y comentarios

---

**ğŸ‰ Â¡Staging Pipeline Completado!**

Has completado exitosamente el **Paso 4** del Taller 2. El ambiente staging estÃ¡ configurado, las pruebas estÃ¡n ejecutÃ¡ndose, y el sistema estÃ¡ listo para la promociÃ³n a producciÃ³n.

**ğŸ“ˆ Progreso del Taller 2:**
- âœ… Paso 1: Jenkins/Docker/Kubernetes (10%)
- âœ… Paso 2: Dev pipelines (15%)
- âœ… Paso 3: Testing comprensivo (30%)
- âœ… **Paso 4: Stage pipelines (15%)** â† **Â¡COMPLETADO!**
- â³ Paso 5: Production deployment (15%)
- â³ Paso 6: Documentation (15%)

**ğŸ¯ Total completado: 70%**

---

## ğŸ“– **RECURSOS ADICIONALES STAGING**

### ğŸ”— Enlaces Ãštiles
- [Docker Compose Documentation](https://docs.docker.com/compose/)
- [Spring Boot Profiles](https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.profiles)
- [Jenkins Pipeline Documentation](https://www.jenkins.io/doc/book/pipeline/)
- [Eureka Service Discovery](https://spring.io/projects/spring-cloud-netflix)

### ğŸ“š Lecturas Recomendadas
- "Continuous Delivery" - Jez Humble & David Farley
- "The DevOps Handbook" - Gene Kim, Patrick Debois
- "Infrastructure as Code" - Kief Morris

---

*Documento actualizado para incluir Stage Pipelines - Paso 4 del Taller 2* 